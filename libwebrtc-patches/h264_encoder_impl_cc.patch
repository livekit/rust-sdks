diff --git org/webrtc-sys/libwebrtc/src/modules/video_coding/codecs/h264/h264_encoder_impl.cc update/webrtc-sys/libwebrtc/src/modules/video_coding/codecs/h264/h264_encoder_impl.cc
index b6023ac..1a23348 100644
--- org/webrtc-sys/libwebrtc/src/modules/video_coding/codecs/h264/h264_encoder_impl.cc
+++ update/webrtc-sys/libwebrtc/src/modules/video_coding/codecs/h264/h264_encoder_impl.cc
@@ -12,11 +12,13 @@
 // Everything declared/defined in this header is only required when WebRTC is
 // build with H264 support, please do not move anything out of the
 // #ifdef unless needed and tested.
+
 #ifdef WEBRTC_USE_H264
 
 #include "modules/video_coding/codecs/h264/h264_encoder_impl.h"
 
 #include <algorithm>
+#include <iostream>
 #include <limits>
 #include <string>
 
@@ -171,7 +173,8 @@ static void RtpFragmentize(EncodedImage* encoded_image, SFrameBSInfo* info) {
 }
 
 H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
-    : packetization_mode_(H264PacketizationMode::SingleNalUnit),
+    : useHWEncoder_(false),
+      packetization_mode_(H264PacketizationMode::SingleNalUnit),
       max_payload_size_(0),
       number_of_cores_(0),
       encoded_image_callback_(nullptr),
@@ -190,14 +193,42 @@ H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
   configurations_.reserve(kMaxSimulcastStreams);
   tl0sync_limit_.reserve(kMaxSimulcastStreams);
   svc_controllers_.reserve(kMaxSimulcastStreams);
+
+  // Use the following lines to enable logging for debugging
+  // rtc::LogMessage::LogToDebug(rtc::LS_VERBOSE);
+  // rtc::LogMessage::SetLogToStderr(true);
+
+  vplVideoEncoder_ =
+      std::make_unique<any_vpl::VplVideoEncoder>(kVideoCodecH264);
+  if (!vplVideoEncoder_) {
+    useHWEncoder_ = false;
+    RTC_LOG(LS_ERROR) << "Failed to create VplVideoEncoder";
+    return;
+  }
 }
 
 H264EncoderImpl::~H264EncoderImpl() {
+  if (useHWEncoder_) {
+    vplVideoEncoder_->Release();
+    return;
+  }
+
   Release();
 }
 
 int32_t H264EncoderImpl::InitEncode(const VideoCodec* inst,
                                     const VideoEncoder::Settings& settings) {
+  const int32_t retVal = vplVideoEncoder_->InitEncode(
+      inst, settings.number_of_cores, settings.max_payload_size);
+  useHWEncoder_ = (retVal == WEBRTC_VIDEO_CODEC_OK) ? true : false;
+
+  if (useHWEncoder_) {
+    return retVal;
+  }
+
+  RTC_LOG(LS_WARNING)
+      << "Failed to initialize VplVideoEncoder. Using software encoder.";
+
   ReportInit();
   if (!inst || inst->codecType != kVideoCodecH264) {
     ReportError();
@@ -239,8 +270,8 @@ int32_t H264EncoderImpl::InitEncode(const VideoCodec* inst,
   encoder_thread_limit_ = settings.encoder_thread_limit;
   codec_ = *inst;
 
-  // Code expects simulcastStream resolutions to be correct, make sure they are
-  // filled even when there are no simulcast layers.
+  // Code expects simulcastStream resolutions to be correct, make sure they
+  // are filled even when there are no simulcast layers.
   if (codec_.numberOfSimulcastStreams == 0) {
     codec_.simulcastStream[0].width = codec_.width;
     codec_.simulcastStream[0].height = codec_.height;
@@ -339,6 +370,10 @@ int32_t H264EncoderImpl::InitEncode(const VideoCodec* inst,
 }
 
 int32_t H264EncoderImpl::Release() {
+  if (useHWEncoder_) {
+    return vplVideoEncoder_->Release();
+  }
+
   while (!encoders_.empty()) {
     ISVCEncoder* openh264_encoder = encoders_.back();
     if (openh264_encoder) {
@@ -359,11 +394,19 @@ int32_t H264EncoderImpl::Release() {
 
 int32_t H264EncoderImpl::RegisterEncodeCompleteCallback(
     EncodedImageCallback* callback) {
+  if (useHWEncoder_) {
+    return vplVideoEncoder_->RegisterEncodeCompleteCallback(callback);
+  }
+
   encoded_image_callback_ = callback;
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
 void H264EncoderImpl::SetRates(const RateControlParameters& parameters) {
+  if (useHWEncoder_) {
+    return vplVideoEncoder_->SetRates(parameters);
+  }
+
   if (encoders_.empty()) {
     RTC_LOG(LS_WARNING) << "SetRates() while uninitialized.";
     return;
@@ -411,6 +454,10 @@ void H264EncoderImpl::SetRates(const RateControlParameters& parameters) {
 int32_t H264EncoderImpl::Encode(
     const VideoFrame& input_frame,
     const std::vector<VideoFrameType>* frame_types) {
+  if (useHWEncoder_) {
+    return vplVideoEncoder_->Encode(input_frame, frame_types);
+  }
+
   if (encoders_.empty()) {
     ReportError();
     return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
@@ -439,8 +486,8 @@ int32_t H264EncoderImpl::Encode(
   for (size_t i = 0; i < configurations_.size(); ++i) {
     if (configurations_[i].key_frame_request && configurations_[i].sending) {
       // This is legacy behavior, generating a keyframe on all layers
-      // when generating one for a layer that became active for the first time
-      // or after being disabled.
+      // when generating one for a layer that became active for the first
+      // time or after being disabled.
       is_keyframe_needed = true;
       break;
     }
@@ -506,7 +553,8 @@ int32_t H264EncoderImpl::Encode(
          (*frame_types)[simulcast_idx] == VideoFrameType::kVideoFrameKey);
     if (send_key_frame) {
       // API doc says ForceIntraFrame(false) does nothing, but calling this
-      // function forces a key frame regardless of the `bIDR` argument's value.
+      // function forces a key frame regardless of the `bIDR` argument's
+      // value.
       // (If every frame is a key frame we get lag/delays.)
       encoders_[i]->ForceIntraFrame(true);
       configurations_[i].key_frame_request = false;
@@ -702,6 +750,10 @@ void H264EncoderImpl::ReportError() {
 }
 
 VideoEncoder::EncoderInfo H264EncoderImpl::GetEncoderInfo() const {
+  if (useHWEncoder_) {
+    return vplVideoEncoder_->GetEncoderInfo();
+  }
+
   EncoderInfo info;
   info.supports_native_handle = false;
   info.implementation_name = "OpenH264";
